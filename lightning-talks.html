<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Lightning talks | e-Rum2020 Program</title>
  <meta name="description" content="1.1 Lightning talks | e-Rum2020 Program" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Lightning talks | e-Rum2020 Program" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Lightning talks | e-Rum2020 Program" />
  
  
  

<meta name="author" content="e-Rum2020 Organizing Committee" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="erum2020-contributed-program.html"/>
<link rel="next" href="posters.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Index</a></li>
<li class="chapter" data-level="1" data-path="erum2020-contributed-program.html"><a href="erum2020-contributed-program.html"><i class="fa fa-check"></i><b>1</b> eRum2020 Contributed Program</a><ul>
<li class="chapter" data-level="1.1" data-path="lightning-talks.html"><a href="lightning-talks.html"><i class="fa fa-check"></i><b>1.1</b> Lightning talks</a><ul>
<li class="chapter" data-level="1.1.1" data-path="lightning-talks.html"><a href="lightning-talks.html#an-enriched-disease-risk-assessment-model-based-on-historical-blood-donors-records"><i class="fa fa-check"></i><b>1.1.1</b> An enriched disease risk assessment model based on historical blood donors records</a></li>
<li class="chapter" data-level="1.1.2" data-path="lightning-talks.html"><a href="lightning-talks.html#rdwd-r-interface-to-german-weather-service-data"><i class="fa fa-check"></i><b>1.1.2</b> rdwd: R interface to German Weather Service data</a></li>
<li class="chapter" data-level="1.1.3" data-path="lightning-talks.html"><a href="lightning-talks.html#tv-show-data-frames-in-the-browser"><i class="fa fa-check"></i><b>1.1.3</b> tv: Show Data Frames in the Browser</a></li>
<li class="chapter" data-level="1.1.4" data-path="lightning-talks.html"><a href="lightning-talks.html#predicting-the-euro-2020-results-using-tournament-rank-probabilities-scores-from-the-soccer-package"><i class="fa fa-check"></i><b>1.1.4</b> Predicting the Euro 2020 results using tournament rank probabilities scores from the socceR package</a></li>
<li class="chapter" data-level="1.1.5" data-path="lightning-talks.html"><a href="lightning-talks.html#differential-enriched-scan-2-descan2-an-r-pipeline-for-epigenomic-analysis."><i class="fa fa-check"></i><b>1.1.5</b> Differential Enriched Scan 2 (DEScan2): an R pipeline for epigenomic analysis.</a></li>
<li class="chapter" data-level="1.1.6" data-path="lightning-talks.html"><a href="lightning-talks.html#ultra-fast-penalized-regressions-with-r-package-bigstatsr"><i class="fa fa-check"></i><b>1.1.6</b> Ultra fast penalized regressions with R package {bigstatsr}</a></li>
<li class="chapter" data-level="1.1.7" data-path="lightning-talks.html"><a href="lightning-talks.html#supporting-twitter-analytics-application-with-graph-databases-and-the-arangodb-package"><i class="fa fa-check"></i><b>1.1.7</b> Supporting Twitter analytics application with graph-databases and the aRangodb package</a></li>
<li class="chapter" data-level="1.1.8" data-path="lightning-talks.html"><a href="lightning-talks.html#reproducible-data-visualization-with-canvasxpress"><i class="fa fa-check"></i><b>1.1.8</b> Reproducible Data Visualization with CanvasXpress</a></li>
<li class="chapter" data-level="1.1.9" data-path="lightning-talks.html"><a href="lightning-talks.html#design-your-own-quantum-simulator-with-r"><i class="fa fa-check"></i><b>1.1.9</b> Design your own quantum simulator with R</a></li>
<li class="chapter" data-level="1.1.10" data-path="lightning-talks.html"><a href="lightning-talks.html#what-are-the-potato-eaters-eating"><i class="fa fa-check"></i><b>1.1.10</b> What are the potato eaters eating</a></li>
<li class="chapter" data-level="1.1.11" data-path="lightning-talks.html"><a href="lightning-talks.html#dm-working-with-relational-data-models-in-r"><i class="fa fa-check"></i><b>1.1.11</b> dm: working with relational data models in R</a></li>
<li class="chapter" data-level="1.1.12" data-path="lightning-talks.html"><a href="lightning-talks.html#explaining-black-box-models-with-xspliner-to-make-deliberate-business-decisions"><i class="fa fa-check"></i><b>1.1.12</b> Explaining black-box models with xspliner to make deliberate business decisions</a></li>
<li class="chapter" data-level="1.1.13" data-path="lightning-talks.html"><a href="lightning-talks.html#using-open-access-data-to-derive-genome-composition-of-emerging-viruses"><i class="fa fa-check"></i><b>1.1.13</b> Using open-access data to derive genome composition of emerging viruses</a></li>
<li class="chapter" data-level="1.1.14" data-path="lightning-talks.html"><a href="lightning-talks.html#a-principal-component-analysis-based-method-to-detect-biomarker-captation-from-vibrational-spectra"><i class="fa fa-check"></i><b>1.1.14</b> A principal component analysis based method to detect biomarker captation from vibrational spectra</a></li>
<li class="chapter" data-level="1.1.15" data-path="lightning-talks.html"><a href="lightning-talks.html#an-innovative-way-to-support-your-sales-force"><i class="fa fa-check"></i><b>1.1.15</b> An innovative way to support your sales force</a></li>
<li class="chapter" data-level="1.1.16" data-path="lightning-talks.html"><a href="lightning-talks.html#ptmixed-an-r-package-for-flexible-modelling-of-longitudinal-overdispersed-count-data"><i class="fa fa-check"></i><b>1.1.16</b> ptmixed: an R package for flexible modelling of longitudinal overdispersed count data</a></li>
<li class="chapter" data-level="1.1.17" data-path="lightning-talks.html"><a href="lightning-talks.html#one-way-non-normal-anova-in-reliability-analysis-using-with-doex"><i class="fa fa-check"></i><b>1.1.17</b> One-way non-normal ANOVA in reliability analysis using with doex</a></li>
<li class="chapter" data-level="1.1.18" data-path="lightning-talks.html"><a href="lightning-talks.html#keeping-on-top-of-r-in-real-time-high-stakes-trading-systems"><i class="fa fa-check"></i><b>1.1.18</b> Keeping on top of R in Real-Time, High-Stakes trading systems</a></li>
<li class="chapter" data-level="1.1.19" data-path="lightning-talks.html"><a href="lightning-talks.html#towards-more-structured-data-quality-assessment-in-the-process-mining-field-the-daqapo-package"><i class="fa fa-check"></i><b>1.1.19</b> Towards more structured data quality assessment in the process mining field: the DaQAPO package</a></li>
<li class="chapter" data-level="1.1.20" data-path="lightning-talks.html"><a href="lightning-talks.html#analyzing-preference-data-with-the-bayesmallows-package"><i class="fa fa-check"></i><b>1.1.20</b> Analyzing Preference Data with the BayesMallows Package</a></li>
<li class="chapter" data-level="1.1.21" data-path="lightning-talks.html"><a href="lightning-talks.html#predicting-business-cycle-fluctuations-using-text-analytics"><i class="fa fa-check"></i><b>1.1.21</b> Predicting Business Cycle Fluctuations Using Text Analytics</a></li>
<li class="chapter" data-level="1.1.22" data-path="lightning-talks.html"><a href="lightning-talks.html#flexible-deep-learning-via-the-juliaconnector"><i class="fa fa-check"></i><b>1.1.22</b> Flexible deep learning via the JuliaConnectoR</a></li>
<li class="chapter" data-level="1.1.23" data-path="lightning-talks.html"><a href="lightning-talks.html#time-series-missing-data-visualizations"><i class="fa fa-check"></i><b>1.1.23</b> Time Series Missing Data Visualizations</a></li>
<li class="chapter" data-level="1.1.24" data-path="lightning-talks.html"><a href="lightning-talks.html#effectclass-an-r-package-to-interpret-effects-and-visualise-uncertainty"><i class="fa fa-check"></i><b>1.1.24</b> effectclass: an R package to interpret effects and visualise uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="posters.html"><a href="posters.html"><i class="fa fa-check"></i><b>1.2</b> Posters</a><ul>
<li class="chapter" data-level="1.2.1" data-path="posters.html"><a href="posters.html#a-flexible-dashboard-for-monitoring-platform-trials"><i class="fa fa-check"></i><b>1.2.1</b> A flexible dashboard for monitoring platform trials</a></li>
<li class="chapter" data-level="1.2.2" data-path="posters.html"><a href="posters.html#prda-package-enhancing-statistical-inference-via-prospective-and-retrospective-design-analysis."><i class="fa fa-check"></i><b>1.2.2</b> PRDA package: Enhancing Statistical Inference via Prospective and Retrospective Design Analysis.</a></li>
<li class="chapter" data-level="1.2.3" data-path="posters.html"><a href="posters.html#automate-flexdashboard-with-github"><i class="fa fa-check"></i><b>1.2.3</b> Automate flexdashboard with GitHub</a></li>
<li class="chapter" data-level="1.2.4" data-path="posters.html"><a href="posters.html#easyreporting-a-bioconductor-package-for-reproducible-research-implementation"><i class="fa fa-check"></i><b>1.2.4</b> EasyReporting: a Bioconductor package for Reproducible Research implementation</a></li>
<li class="chapter" data-level="1.2.5" data-path="posters.html"><a href="posters.html#newwave-a-scalable-r-package-for-the-dimensionality-reduction-of-single-cell-rna-seq"><i class="fa fa-check"></i><b>1.2.5</b> NewWave: a scalable R package for the dimensionality reduction of single-cell RNA-seq</a></li>
<li class="chapter" data-level="1.2.6" data-path="posters.html"><a href="posters.html#orf-ordered-random-forests"><i class="fa fa-check"></i><b>1.2.6</b> orf: Ordered Random Forests</a></li>
<li class="chapter" data-level="1.2.7" data-path="posters.html"><a href="posters.html#power-supply-health-status-monitoring-dashboard"><i class="fa fa-check"></i><b>1.2.7</b> Power Supply health status monitoring dashboard</a></li>
<li class="chapter" data-level="1.2.8" data-path="posters.html"><a href="posters.html#first-year-ict-students-dropout-predicting-with-r-models"><i class="fa fa-check"></i><b>1.2.8</b> First-year ICT students dropout predicting with R models</a></li>
<li class="chapter" data-level="1.2.9" data-path="posters.html"><a href="posters.html#benchmark-percentage-disjoint-data-splitting-in-cross-validation-for-assessing-the-skill-of-machine"><i class="fa fa-check"></i><b>1.2.9</b> Benchmark Percentage Disjoint Data Splitting in Cross Validation for Assessing the Skill of Machine</a></li>
<li class="chapter" data-level="1.2.10" data-path="posters.html"><a href="posters.html#integrating-professional-software-engineering-practices-in-medical-research-software"><i class="fa fa-check"></i><b>1.2.10</b> Integrating professional software engineering practices in medical research software</a></li>
<li class="chapter" data-level="1.2.11" data-path="posters.html"><a href="posters.html#dealing-with-changing-administrative-boundaries-the-case-of-swiss-municipalities"><i class="fa fa-check"></i><b>1.2.11</b> Dealing with changing administrative boundaries: The case of Swiss municipalities</a></li>
<li class="chapter" data-level="1.2.12" data-path="posters.html"><a href="posters.html#baddea-an-r-package-for-measuring-firms-efficiency-adjusted-by-undesirable-outputs"><i class="fa fa-check"></i><b>1.2.12</b> badDEA: An R package for measuring firms’ efficiency adjusted by undesirable outputs</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="regular-talks.html"><a href="regular-talks.html"><i class="fa fa-check"></i><b>1.3</b> Regular talks</a><ul>
<li class="chapter" data-level="1.3.1" data-path="regular-talks.html"><a href="regular-talks.html#design-patterns-for-big-shiny-apps"><i class="fa fa-check"></i><b>1.3.1</b> Design Patterns For Big Shiny Apps</a></li>
<li class="chapter" data-level="1.3.2" data-path="regular-talks.html"><a href="regular-talks.html#using-xgboost-plumber-and-docker-in-production-to-power-a-new-banking-product"><i class="fa fa-check"></i><b>1.3.2</b> Using XGBoost, Plumber and Docker in production to power a new banking product</a></li>
<li class="chapter" data-level="1.3.3" data-path="regular-talks.html"><a href="regular-talks.html#astronomical-source-detection-and-background-separation-a-bayesian-nonparametric-approach"><i class="fa fa-check"></i><b>1.3.3</b> Astronomical source detection and background separation: a Bayesian nonparametric approach</a></li>
<li class="chapter" data-level="1.3.4" data-path="regular-talks.html"><a href="regular-talks.html#creating-drag-and-drop-shiny-applications-using-sortable"><i class="fa fa-check"></i><b>1.3.4</b> Creating drag-and-drop shiny applications using sortable</a></li>
<li class="chapter" data-level="1.3.5" data-path="regular-talks.html"><a href="regular-talks.html#high-dimensional-sampling-and-volume-computation"><i class="fa fa-check"></i><b>1.3.5</b> High dimensional sampling and volume computation</a></li>
<li class="chapter" data-level="1.3.6" data-path="regular-talks.html"><a href="regular-talks.html#fake-news-ai-on-the-battle-ground"><i class="fa fa-check"></i><b>1.3.6</b> Fake News: AI on the battle ground</a></li>
<li class="chapter" data-level="1.3.7" data-path="regular-talks.html"><a href="regular-talks.html#from-consulting-to-open-source-and-back"><i class="fa fa-check"></i><b>1.3.7</b> From consulting to open-source and back</a></li>
<li class="chapter" data-level="1.3.8" data-path="regular-talks.html"><a href="regular-talks.html#deduplicating-real-estate-ads-using-naive-bayes-record-linkage"><i class="fa fa-check"></i><b>1.3.8</b> Deduplicating real estate ads using Naive Bayes record linkage</a></li>
<li class="chapter" data-level="1.3.9" data-path="regular-talks.html"><a href="regular-talks.html#polite-web-etiquette-for-r-users"><i class="fa fa-check"></i><b>1.3.9</b> {polite}: web etiquette for R users</a></li>
<li class="chapter" data-level="1.3.10" data-path="regular-talks.html"><a href="regular-talks.html#hydrological-modelling-and-r"><i class="fa fa-check"></i><b>1.3.10</b> Hydrological Modelling and R</a></li>
<li class="chapter" data-level="1.3.11" data-path="regular-talks.html"><a href="regular-talks.html#genetonic-enjoy-rna-seq-data-analysis-responsibly"><i class="fa fa-check"></i><b>1.3.11</b> GeneTonic: enjoy RNA-seq data analysis, responsibly</a></li>
<li class="chapter" data-level="1.3.12" data-path="regular-talks.html"><a href="regular-talks.html#a-simple-and-flexible-inactivitysleep-detection-r-package"><i class="fa fa-check"></i><b>1.3.12</b> A simple and flexible inactivity/sleep detection R package</a></li>
<li class="chapter" data-level="1.3.13" data-path="regular-talks.html"><a href="regular-talks.html#progressr-an-inclusive-unifying-api-for-progress-updates"><i class="fa fa-check"></i><b>1.3.13</b> progressr: An Inclusive, Unifying API for Progress Updates</a></li>
<li class="chapter" data-level="1.3.14" data-path="regular-talks.html"><a href="regular-talks.html#varycoef-modeling-spatially-varying-coefficients"><i class="fa fa-check"></i><b>1.3.14</b> varycoef: Modeling Spatially Varying Coefficients</a></li>
<li class="chapter" data-level="1.3.15" data-path="regular-talks.html"><a href="regular-talks.html#fastai-in-r-preserving-wildlife-with-computer-vision"><i class="fa fa-check"></i><b>1.3.15</b> FastAI in R: preserving wildlife with computer vision</a></li>
<li class="chapter" data-level="1.3.16" data-path="regular-talks.html"><a href="regular-talks.html#the-r-consortium-2020-adapting-to-rapid-change-and-global-crisis"><i class="fa fa-check"></i><b>1.3.16</b> The R Consortium 2020: adapting to rapid change and global crisis</a></li>
<li class="chapter" data-level="1.3.17" data-path="regular-talks.html"><a href="regular-talks.html#powering-turing-e-atlas-with-r"><i class="fa fa-check"></i><b>1.3.17</b> Powering Turing e-Atlas with R</a></li>
<li class="chapter" data-level="1.3.18" data-path="regular-talks.html"><a href="regular-talks.html#using-process-mining-principles-to-extract-a-collaboration-graph-from-a-version-control-system-log"><i class="fa fa-check"></i><b>1.3.18</b> Using process mining principles to extract a collaboration graph from a version control system log</a></li>
<li class="chapter" data-level="1.3.19" data-path="regular-talks.html"><a href="regular-talks.html#manifoldgstat-an-r-package-for-spatial-statistics-of-manifold-data"><i class="fa fa-check"></i><b>1.3.19</b> Manifoldgstat: an R package for spatial statistics of manifold data</a></li>
<li class="chapter" data-level="1.3.20" data-path="regular-talks.html"><a href="regular-talks.html#voronoi-linkage-for-spatially-misaligned-data"><i class="fa fa-check"></i><b>1.3.20</b> Voronoi Linkage for Spatially Misaligned Data</a></li>
<li class="chapter" data-level="1.3.21" data-path="regular-talks.html"><a href="regular-talks.html#be-proud-of-your-code-tools-and-patterns-for-making-production-ready-clean-r-code"><i class="fa fa-check"></i><b>1.3.21</b> Be proud of your code! Tools and patterns for making production-ready, clean R code</a></li>
<li class="chapter" data-level="1.3.22" data-path="regular-talks.html"><a href="regular-talks.html#going-in-the-fast-lane-with-r.-how-we-use-r-within-the-biggest-digital-dealer-program-in-emea."><i class="fa fa-check"></i><b>1.3.22</b> Going in the fast lane with R. How we use R within the biggest digital dealer program in EMEA.</a></li>
<li class="chapter" data-level="1.3.23" data-path="regular-talks.html"><a href="regular-talks.html#r-alongside-airflow-docker-and-gitlab-ci"><i class="fa fa-check"></i><b>1.3.23</b> R alongside Airflow, Docker and Gitlab CI</a></li>
<li class="chapter" data-level="1.3.24" data-path="regular-talks.html"><a href="regular-talks.html#damirseq-2.0-from-high-dimensional-data-to-cost-effective-reliable-prediction-models"><i class="fa fa-check"></i><b>1.3.24</b> DaMiRseq 2.0: from high dimensional data to cost-effective reliable prediction models</a></li>
<li class="chapter" data-level="1.3.25" data-path="regular-talks.html"><a href="regular-talks.html#how-to-apply-r-in-a-hospital-environment-on-standard-available-hospital-wide-data"><i class="fa fa-check"></i><b>1.3.25</b> How to apply R in a hospital environment on standard available hospital-wide data</a></li>
<li class="chapter" data-level="1.3.26" data-path="regular-talks.html"><a href="regular-talks.html#computer-algebra-systems-in-r"><i class="fa fa-check"></i><b>1.3.26</b> Computer Algebra Systems in R</a></li>
<li class="chapter" data-level="1.3.27" data-path="regular-talks.html"><a href="regular-talks.html#interpretable-and-accessible-deep-learning-for-omics-data-with-r-and-friends"><i class="fa fa-check"></i><b>1.3.27</b> Interpretable and accessible Deep Learning for omics data with R and friends</a></li>
<li class="chapter" data-level="1.3.28" data-path="regular-talks.html"><a href="regular-talks.html#elevating-shiny-module-with-tidymodules"><i class="fa fa-check"></i><b>1.3.28</b> Elevating shiny module with {tidymodules}</a></li>
<li class="chapter" data-level="1.3.29" data-path="regular-talks.html"><a href="regular-talks.html#apfr-average-power-function-and-bayes-fdr-for-robust-brain-networks-construction"><i class="fa fa-check"></i><b>1.3.29</b> APFr: Average Power Function and Bayes FDR for Robust Brain Networks Construction</a></li>
<li class="chapter" data-level="1.3.30" data-path="regular-talks.html"><a href="regular-talks.html#flexible-meta-analysis-of-generalized-additive-models-with-metagam"><i class="fa fa-check"></i><b>1.3.30</b> Flexible Meta-Analysis of Generalized Additive Models with metagam</a></li>
<li class="chapter" data-level="1.3.31" data-path="regular-talks.html"><a href="regular-talks.html#epimod-a-computational-framework-for-studying-epidemiological-systems."><i class="fa fa-check"></i><b>1.3.31</b> EPIMOD: A computational framework for studying epidemiological systems.</a></li>
<li class="chapter" data-level="1.3.32" data-path="regular-talks.html"><a href="regular-talks.html#correlaidx---building-r-focused-communities-for-social-good-on-the-local-level"><i class="fa fa-check"></i><b>1.3.32</b> CorrelAidX - Building R-focused Communities for Social Good on the Local Level</a></li>
<li class="chapter" data-level="1.3.33" data-path="regular-talks.html"><a href="regular-talks.html#interactive-visualization-of-complex-texts"><i class="fa fa-check"></i><b>1.3.33</b> Interactive visualization of complex texts</a></li>
<li class="chapter" data-level="1.3.34" data-path="regular-talks.html"><a href="regular-talks.html#connector-a-computational-approach-to-study-intratumor-heterogeneity."><i class="fa fa-check"></i><b>1.3.34</b> CONNECTOR: a computational approach to study intratumor heterogeneity.</a></li>
<li class="chapter" data-level="1.3.35" data-path="regular-talks.html"><a href="regular-talks.html#gwqs-an-r-package-for-linear-and-generalized-weighted-quantile-sum-wqs-regression"><i class="fa fa-check"></i><b>1.3.35</b> gWQS: An R Package for Linear and Generalized Weighted Quantile Sum (WQS) Regression</a></li>
<li class="chapter" data-level="1.3.36" data-path="regular-talks.html"><a href="regular-talks.html#transparent-journalism-through-the-power-of-r"><i class="fa fa-check"></i><b>1.3.36</b> Transparent Journalism Through the Power of R</a></li>
<li class="chapter" data-level="1.3.37" data-path="regular-talks.html"><a href="regular-talks.html#whats-new-in-shinyproxy"><i class="fa fa-check"></i><b>1.3.37</b> What’s New in ShinyProxy</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="shiny-demos.html"><a href="shiny-demos.html"><i class="fa fa-check"></i><b>1.4</b> Shiny demos</a><ul>
<li class="chapter" data-level="1.4.1" data-path="shiny-demos.html"><a href="shiny-demos.html#visualising-and-modelling-bike-sharing-mobility-usage-in-the-city-of-milan"><i class="fa fa-check"></i><b>1.4.1</b> Visualising and Modelling Bike Sharing Mobility usage in the city of Milan</a></li>
<li class="chapter" data-level="1.4.2" data-path="shiny-demos.html"><a href="shiny-demos.html#media-shiny-marketing-mix-models-builder"><i class="fa fa-check"></i><b>1.4.2</b> Media Shiny: Marketing Mix Models Builder</a></li>
<li class="chapter" data-level="1.4.3" data-path="shiny-demos.html"><a href="shiny-demos.html#espres-a-shiny-web-tool-to-support-river-basin-management-planning-in-european-watersheds"><i class="fa fa-check"></i><b>1.4.3</b> ESPRES: A shiny web tool to support River Basin Management planning in European Watersheds</a></li>
<li class="chapter" data-level="1.4.4" data-path="shiny-demos.html"><a href="shiny-demos.html#tsviz-a-data-scientist-friendly-addin-for-rstudio"><i class="fa fa-check"></i><b>1.4.4</b> tsviz: a data-scientist-friendly addin for RStudio</a></li>
<li class="chapter" data-level="1.4.5" data-path="shiny-demos.html"><a href="shiny-demos.html#mobility-scan"><i class="fa fa-check"></i><b>1.4.5</b> Mobility scan</a></li>
<li class="chapter" data-level="1.4.6" data-path="shiny-demos.html"><a href="shiny-demos.html#developing-shiny-applications-to-facilitate-precision-agriculture-workflows"><i class="fa fa-check"></i><b>1.4.6</b> Developing Shiny applications to facilitate precision agriculture workflows</a></li>
<li class="chapter" data-level="1.4.7" data-path="shiny-demos.html"><a href="shiny-demos.html#guinterp-a-shiny-gui-to-support-spatial-interpolation"><i class="fa fa-check"></i><b>1.4.7</b> “GUInterp”: a Shiny GUI to support spatial interpolation</a></li>
<li class="chapter" data-level="1.4.8" data-path="shiny-demos.html"><a href="shiny-demos.html#a-demonstration-of-abacus-apps-based-activities-for-communicating-and-understanding-statistics"><i class="fa fa-check"></i><b>1.4.8</b> A demonstration of ABACUS: Apps Based Activities for Communicating and Understanding Statistics</a></li>
<li class="chapter" data-level="1.4.9" data-path="shiny-demos.html"><a href="shiny-demos.html#scoring-the-implicit-association-test-has-never-been-easier-dscoreapp"><i class="fa fa-check"></i><b>1.4.9</b> Scoring the Implicit Association Test has never been easier: DscoreApp</a></li>
<li class="chapter" data-level="1.4.10" data-path="shiny-demos.html"><a href="shiny-demos.html#rtrhexng-hexagon-sticker-app-for-rtrng"><i class="fa fa-check"></i><b>1.4.10</b> rTRhexNG: Hexagon sticker app for rTRNG</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">e-Rum2020 Program</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lightning-talks" class="section level2">
<h2><span class="header-section-number">1.1</span> Lightning talks</h2>
<div id="an-enriched-disease-risk-assessment-model-based-on-historical-blood-donors-records" class="section level3">
<h3><span class="header-section-number">1.1.1</span> An enriched disease risk assessment model based on historical blood donors records</h3>
<p><strong>Andrea Cappozzo</strong>, <em>PhD student at University of Milan-Bicocca</em></p>
<p>Track(s): R Applications</p>
<p><strong>Abstract:</strong></p>
<p>Historically, the medical literature has largely focused on determining risk factors at an illness-specific level. Nevertheless, recent studies suggested that identical risk factors may cause the appearance of different diseases in different patients (Meijers &amp; De Boer, 2019).</p>
<p>Thanks to the joint collaboration of Heartindata, a group of data scientists offering their passion and skills for social good, and Avis Milano, the Italian blood donor organization, an enriched disease risk assessment model is developed. Multiple risk factors and donations drop-out causes are collectively analyzed from AVIS longitudinal records, with the final aim of providing a broader and clearer overview of the interplay between risk factors and associated diseases in the blood donors population.</p>
<p>Coauthor(s): Edoardo Michielon, Alessandro De Bettin, Chiara D’Ignazio, Luigi Noto, Davide Drago, Alberto Prospero, Francesca De Chiara, Sergio Casartelli .</p>
</div>
<div id="rdwd-r-interface-to-german-weather-service-data" class="section level3">
<h3><span class="header-section-number">1.1.2</span> rdwd: R interface to German Weather Service data</h3>
<p><strong>Berry Boessenkool</strong>, <em>R trainer &amp; consultant</em></p>
<p>Track(s): R Applications</p>
<p><strong>Abstract:</strong></p>
<p>rdwd is an R package to handle data from the German Weather Service (DWD). It allows to easily select, download and read observational data from over 6k weather stations. Both current data and historical records (partially dating back to the 1860s) are handled. Since about a year, gridded data from radar measurements can be read as well.</p>
</div>
<div id="tv-show-data-frames-in-the-browser" class="section level3">
<h3><span class="header-section-number">1.1.3</span> tv: Show Data Frames in the Browser</h3>
<p><strong>Christoph Sax</strong>, <em>R-enthusiast, economist <span class="citation">@cynkra</span></em></p>
<p>Track(s): R World</p>
<p><strong>Abstract:</strong></p>
<p>The tv package lively displays data frames during data analysis.
It modifies the print method of data frames, tibbles or data tables to also appear in a browser or in the view pane of RStudio.</p>
<p>This is similar in spirit to the View() function in RStudio, works in other development environments, and has several advantages.
Changes in data frame are shown immediately and next to the script and the console output, rather than on top of them.
The display keeps the position and the width of columns if a modified data frame is shown in tv.
It is updated asynchronously, without interrupting the analysis workflow.</p>
<p>Coauthor(s): Kirill Müller .</p>
</div>
<div id="predicting-the-euro-2020-results-using-tournament-rank-probabilities-scores-from-the-soccer-package" class="section level3">
<h3><span class="header-section-number">1.1.4</span> Predicting the Euro 2020 results using tournament rank probabilities scores from the socceR package</h3>
<p><strong>Claus Ekstrøm</strong>, <em>Statistician at University of Copenhagen. Longtime R hacker.</em></p>
<p>Track(s): R Applications</p>
<p><strong>Abstract:</strong></p>
<p>The 2020 UEFA European Football Championship will be played this summer. Football championships are the source of almost endless predictions about the winner and the results of the individual matches, and we will show how the recently developed tournament rank probability score can be used to compare predictions.</p>
<p>Different statistical models form the basis for predicting the result of individual matches. We present an R framework for comparing different prediction models and for comparing predictions about the Euro results. Everyone is encouraged to contribute their own function to make predictions for the result of the Euro 2020 championship.</p>
<p>Each contributer will be shown how to provide two functions: a
function that predicts the final score for a match between two teams with different skill levels, and a function that updates the
skill levels based on the results of a given match. By supplying these two functions to the R framework the prediction results can be compared and the winner of the best football predictor can be found when Euro 2020 finishes.</p>
</div>
<div id="differential-enriched-scan-2-descan2-an-r-pipeline-for-epigenomic-analysis." class="section level3">
<h3><span class="header-section-number">1.1.5</span> Differential Enriched Scan 2 (DEScan2): an R pipeline for epigenomic analysis.</h3>
<p><strong>Dario Righelli</strong>, <em>Department of Statistics, University of Padua, Post-Doc</em></p>
<p>Track(s): R Life Sciences</p>
<p><strong>Abstract:</strong></p>
<p>We present DEScan2, a R/Bioconductor package for the differential enrichment analysis of epigenomic sequencing data.
Our method consists of three steps: peak caller, peak consensus across samples, and peak signal quantification.
The peak caller is a standard moving scan window comparing the counts between a sliding window and a larger region outside the window, using a Poisson likelihood, providing a z-score for each peak. However, the package can work with any external peak caller: to this end, we provide additional functionalities to load peaks from bed files and handle them as internal optimized structures.
The consensus step aims to determine if a peak is a “true peak” based on its replicability across samples: we developed a filtering step to filter out those peaks not present in at least a user given number of samples. A further threshold can be used over the peak z-scores.
Finally, the third step produces a count matrix where each column is a sample and each row a previously filtered peak. The value of each matrix cell is the number of reads for the peak in the sample.
Furthermore, our package provides several functionalities for common genomic data structure handling, for instance, to give the possibility to split the data over the chromosomes to speed-up the computations parallelizing them on multiple CPUs.</p>
<p>Coauthor(s): Koberstein John, Gomes Bruce, Zhang Nancy, Angelini Claudia, Peixoto Lucia, Risso Davide .</p>
</div>
<div id="ultra-fast-penalized-regressions-with-r-package-bigstatsr" class="section level3">
<h3><span class="header-section-number">1.1.6</span> Ultra fast penalized regressions with R package {bigstatsr}</h3>
<p><strong>Florian Privé</strong>, <em>Postdoc at Aarhus University</em></p>
<p>Track(s): R Machine Learning &amp; Models</p>
<p><strong>Abstract:</strong></p>
<p>In this talk, I introduce the implementations of penalized linear and logistic regressions as implemented in R package {bigstatsr}.
These implementations use data stored on disk to handle very large matrices.
They automatically perform a procedure similar to cross-validation to choose the two hyper-parameters, λ and α, of the elastic net regularization, in parallel.
They employ an early stopping criterion to avoid fitting very expensive models, making these implementations on average 10 times faster than with {glmnet}.
However, package {bigstatsr} does not implement all the many models and options provided by the excellent package {glmnet}; some are area of future development.</p>
</div>
<div id="supporting-twitter-analytics-application-with-graph-databases-and-the-arangodb-package" class="section level3">
<h3><span class="header-section-number">1.1.7</span> Supporting Twitter analytics application with graph-databases and the aRangodb package</h3>
<p><strong>Gabriele Galatolo</strong>, <em>Kode Srl, Software Developer &amp; Data Scientist</em></p>
<p>Track(s): R Applications</p>
<p><strong>Abstract:</strong></p>
<p>The importance of finding efficient ways to model and to store unstructured data has incredibly grown in the last decade, in particular with the strong expansion of social-media services. Among those storing tools an increasingly important class of databases is represented by the graph-oriented databases, where relationships between data are considered first-class citizens.
In order to support the analyst or the data scientist to interact and use in a simple way with this paradigm, we developed last year the package aRangodb, an interface with the graph-oriented database ArangoDB.
To show the capabilities of the package and of the underlying way to model data using graphs we present Tweetmood, a tool to analyze and visualize tweets from Twitter.
In this talk, we will present some of the most significant features of the package applied in the Tweetmood context, such as functionalities to traverse the graph and some examples in which the user can elaborate those graphs to get new information that can easily be stored using the functions and the tools available in the package.</p>
<p>Coauthor(s): Francesca Giorgolo, Ilaria Ceppa, Marco Calderisi, Davide Massidda, Matteo Papi, Andrea Spinelli, Andrea Zedda, Jacopo Baldacci, Caterina Giacomelli .</p>
</div>
<div id="reproducible-data-visualization-with-canvasxpress" class="section level3">
<h3><span class="header-section-number">1.1.8</span> Reproducible Data Visualization with CanvasXpress</h3>
<p><strong>Ger Inberg</strong>, <em>Freelance Analytics Developer</em></p>
<p>Track(s): R Dataviz &amp; Shiny</p>
<p><strong>Abstract:</strong></p>
<p>canvasXpress was developed as the core visualization component for bioinformatics and systems biology analysis at Bristol-Myers Squibb. It supports a large number of visualizations to display scientific and non-scientific data. canvasXpress also includes a simple and unobtrusive user interface to explore complex data sets, a sophisticated and unique mechanism to keep track of all user customization for Reproducible Research purposes, as well as an ‘out of the box’ broadcasting capability to synchronize selected data points in all canvasXpress plots in a page. Data can be easily sorted, grouped, transposed, transformed or clustered dynamically. The fully customizable mouse events as well as the zooming, panning and drag-and-drop capabilities are features that make this library unique in its class.</p>
</div>
<div id="design-your-own-quantum-simulator-with-r" class="section level3">
<h3><span class="header-section-number">1.1.9</span> Design your own quantum simulator with R</h3>
<p><strong>Indranil Ghosh</strong>, <em>Final year post Graduate student from the department of Physics, Jadavpur University, Kolkata, India</em></p>
<p>Track(s): R Applications</p>
<p><strong>Abstract:</strong></p>
<p>The main idea of the project is to use the R ecosystem to write computer codes for designing a quantum simulator, for simulating different quantum algorithms. I will start with giving a brief introduction to linear algebra for starting with quantum computation, and how to write your own R codes from scratch to implement them. Then I will take a dive into implementing simple quantum circuits starting with initializing qubits and terminating with a measurement. I will also implement simple quantum algorithms concluding with giving a brief intro to quantum game theory and their simulations with R.</p>
</div>
<div id="what-are-the-potato-eaters-eating" class="section level3">
<h3><span class="header-section-number">1.1.10</span> What are the potato eaters eating</h3>
<p><strong>Keshav Bhatt</strong>, <em>R-fan and independent researcher</em></p>
<p>Track(s): R Applications, R Dataviz &amp; Shiny</p>
<p><strong>Abstract:</strong></p>
<p>Although stereotypes can quite useful they are often not correct. For instance, the Dutch are stereotyped as being potato eaters. While this might have been historically correct, it is not currently accurate. The Dutch sparingly eat potatoes and this paper uses data to disprove the stereotype. To get an impression of Dutch food habits, a popular local website was scraped. Besides its popularity, the website hosts user-generated content, giving a good proxy of Dutch taste-buds.
While it was apparent on the website, lasagna is the most popular dish. Detailed NLP analysis of more than 50,000 recipes showed that potato based dishes are in fact nowhere at the top. This vindicated my belief. Moreover, it shows that the Dutch kitchen is globalizing. Tomato, a hallmark of South Europe is more popular than the Dutch potato. Also observed is the popularity of many herbs in the recipes, which are not a traditional component of the Dutch kitchen.
The world is changing and our kitchens too.
This trend will also be explored for other countries also.</p>
</div>
<div id="dm-working-with-relational-data-models-in-r" class="section level3">
<h3><span class="header-section-number">1.1.11</span> dm: working with relational data models in R</h3>
<p><strong>Kirill Müller</strong>, <em>Clean code, tidy data. Consulting for cynkra, coding in the open.</em></p>
<p>Track(s): R Applications, R Production, R World</p>
<p><strong>Abstract:</strong></p>
<p>Storing all data related to a problem in a single table or data frame (“the dataset”) can result in many repetitive values. Separation into multiple tables helps data quality but requires “merge” or “join” operations. {dm} is a new package that fills a gap in the R ecosystem: it makes working with multiple tables just as easy as working with a single table.</p>
<p>A “data model” consists of tables (both the definition and the data), and primary and foreign keys. The {dm} package combines these concepts with data manipulation powered by the tidyverse: entire data models are handled in a single entity, a “dm” object.</p>
<p>Three principal use cases for {dm} can be identified:</p>
<ol style="list-style-type: decimal">
<li><p>When you consume a data model, {dm} helps access and manipulate a dataset consisting of multiple tables (database or local data frames) through a consistent interface.</p></li>
<li><p>When you use a third-party dataset, {dm} helps normalizing the data to remove redundancies as part of the cleaning process.</p></li>
<li><p>To create a relational data model, you can prepare the data using R and familiar tools and seamlessly export to a database.</p></li>
</ol>
<p>The presentation revolves around these use cases and shows a few applications. The {dm} package is available on GitHub and will be submitted to CRAN in early February.</p>
</div>
<div id="explaining-black-box-models-with-xspliner-to-make-deliberate-business-decisions" class="section level3">
<h3><span class="header-section-number">1.1.12</span> Explaining black-box models with xspliner to make deliberate business decisions</h3>
<p><strong>Krystian Igras</strong>, <em>Data Scientists and Software Engineer at Appsilon</em></p>
<p>Track(s): R Machine Learning &amp; Models</p>
<p><strong>Abstract:</strong></p>
<p>A vast majority of the state of the art ML algorithms are black boxes, meaning it is difficult to understand their inner workings. The more that algorithms are used as decision support systems in everyday life, the greater the necessity of understanding the underlying decision rules. This is important for many reasons, including regulatory issues as well as making sure that the model learned sensible features. You can achieve all that with the xspliner R package that I have created.</p>
<p>One of the most promising methods to explain models is building surrogate models. This can be achieved by inferring Partial Dependence Plot (PDP) curves from the black box model and building Generalised Linear Models based on these curves. The advantage of this approach is that it is model agnostic, which means you can use it regardless of what methods you used to create your model.</p>
<p>From this presentation, you will learn what PDP curves and GLMs are and how you can calculate them based on black box models. We will take a look at an interesting business use case in which we’ll find out whether the original black box model or the surrogate one is a better decision system for our needs. Finally, we will see an example of how you can explain your models using this approach with the xspliner package for R (already available on CRAN!).</p>
</div>
<div id="using-open-access-data-to-derive-genome-composition-of-emerging-viruses" class="section level3">
<h3><span class="header-section-number">1.1.13</span> Using open-access data to derive genome composition of emerging viruses</h3>
<p><strong>Liam Brierley</strong>, <em>MRC Skills Development Fellow, University of Liverpool</em></p>
<p>Track(s): R Life Sciences</p>
<p><strong>Abstract:</strong></p>
<p>Outbreaks of new viruses continue to threaten global health, including pandemic influenza, Ebola virus, and the novel coronavirus ‘nCoV-2019’. Advances in genome sequencing allow access to virus RNA sequences on an unprecedented scale, representing a powerful tool for epidemiologists to understand new viral outbreaks.</p>
<p>We use NCBI’s GenBank, a curated open-access repository containing &gt;200 million genetic sequences (3 million viral sequences) directly submitted by users, representing many individual studies. However, the resulting breadth of data and inconsistencies in metadata present consistent challenges.</p>
<p>We demonstrate our approach using R to address these challenges and a need for reproducibility as data increases. Firstly, we use <code>rentrez</code> to programmatically search, filter, and obtain virus sequences from GenBank. Secondly, we use <code>taxize</code> to resolve pervasive problems of naming conflicts, as virus names are often recorded differently between entries, partly because virus classification is complex and regularly revised. We successfully resolve 428 mammal and bird RNA viruses to species level before extracting sequences.</p>
<p>Obtaining genome sequences of a large inventory of viruses allows us to estimate genomic composition biases, which show promise in predicting virus epidemiology. Ultimately, this pathway will allow better quantification of future epidemic threats.</p>
<p>Coauthor(s): Anna Auer-Fowler, Maya Wardeh, Matthew Baylis, Prudence Wong .</p>
</div>
<div id="a-principal-component-analysis-based-method-to-detect-biomarker-captation-from-vibrational-spectra" class="section level3">
<h3><span class="header-section-number">1.1.14</span> A principal component analysis based method to detect biomarker captation from vibrational spectra</h3>
<p><strong>Marco Calderisi</strong>, <em>Kode srl, CTO</em></p>
<p>Track(s): R Life Sciences</p>
<p><strong>Abstract:</strong></p>
<p>BRAIKER is a microfluidics-Based biosensor aimed to detect biomarkers. The device is responsive to changes of mass and viscosity over its surface. When selected markers react with the sensor, a variation of resonant acoustic frequencies (called harmonics) is produced. A serious problem when examining the data produced by biosensors is the subjectivity of standard method to evaluate the pattern of harmonics. In our research, a method based on the principal component analysis has been applied on vibrational data. An R-Shiny application was developed in order to present data visualizations and multivariate analyses of vibrational spectra. The Shiny application allows to clean and explore data by using interactive data visualisation tools. The principal component analysis is applied to analyse simultaneously the full set of frequencies for multiple experimental runs, reducing the multivariate data set into a small number of components accounting for a component of variance near to that the original data. Functionalised and non-functionalised resonating foils of biosensor can be classified in order to validate the capability of the device to detect biomarkers, lowering the LOD and increasing sensitivity and resolution.</p>
<p>Coauthor(s): Francesca Giorgolo, Ilaria Ceppa, Davide Massidda, Matteo Papi, Gabriele Galatolo, Andre Spinelli, Andrea Zedda, Jacopo Baldacci, Caterina Giacomelli, marco cecchini, matteo agostini .</p>
</div>
<div id="an-innovative-way-to-support-your-sales-force" class="section level3">
<h3><span class="header-section-number">1.1.15</span> An innovative way to support your sales force</h3>
<p><strong>Matilde Grecchi</strong>, <em>Head of Data Science &amp; Innovation <span class="citation">@ZucchettiSpa</span></em></p>
<p>Track(s): R Production, R Dataviz &amp; Shiny, R Machine Learning &amp; Models, R Applications</p>
<p><strong>Abstract:</strong></p>
<p>Explanation of the web application realized in Shiny and deployed in production to support the sales force of Zucchetti. An overview of the overall step followed from data ingestion to modeling, from validation of the model to shiny web-app realization, from deployment in production to continous learning thanks to feedbacks coming from sales force and redemption of customers. All the code is written in R using RStudio. The deployment of the app is done with ShinyProxy.io</p>
</div>
<div id="ptmixed-an-r-package-for-flexible-modelling-of-longitudinal-overdispersed-count-data" class="section level3">
<h3><span class="header-section-number">1.1.16</span> ptmixed: an R package for flexible modelling of longitudinal overdispersed count data</h3>
<p><strong>Mirko Signorelli</strong>, <em>Dept. of Biomedical Data Sciences, Leiden University Medical Center</em></p>
<p>Track(s): R Machine Learning &amp; Models, R Life Sciences</p>
<p><strong>Abstract:</strong></p>
<p>Overdispersion is a commonly encountered feature of count data, and it is usually modelled using the negative binomial (NB) distribution. However, not all overdispersed distributions are created equal: while some are severely zero-inflated, other exhibit heavy tails.
Mounting evidence from many research fields suggests that often NB models cannot fit sufficiently well heavy-tailed or zero-inflated counts. It has been proposed to solve this problem by using the more flexible Poisson-Tweedie (PT) family of distributions, of which the NB is special case. However, current methods based on the PT can only handle cross-sectional datasets and no extension for correlated data is available.
To overcome this limitation we propose a PT mixed-effects model that can be used to flexibly model longitudinal overdispersed counts. To estimate this model we develop a computational pipeline that uses adaptive quadratures to accurately approximate the likelihood of the model, and numeric optimization methods to maximize it. We have implemented this approach in the R package ptmixed, which is published on CRAN.
Besides showcasing the package’s functionalities, we will present an assessment of the accuracy of our estimation procedure, and provide an example application where we analyse longitudinal RNA-seq data, which often exhibit high levels of zero-inflation and heavy tails.</p>
<p>Reference: Signorelli, M., Spitali, P., Tsonaka, R. (2020, in press). Poisson-Tweedie mixed-effects model: a flexible approach for the analysis of longitudinal RNA-seq data. To appear in <em>Statistical Modelling</em>. arXiv preprint: <a href="https://arxiv.org/abs/2004.11193">arXiv:2004.11193</a></p>
<p>Coauthor(s): Roula Tsonaka, Pietro Spitali .</p>
</div>
<div id="one-way-non-normal-anova-in-reliability-analysis-using-with-doex" class="section level3">
<h3><span class="header-section-number">1.1.17</span> One-way non-normal ANOVA in reliability analysis using with doex</h3>
<p><strong>Mustafa CAVUS</strong>, <em>PhD Student <span class="citation">@Eskisehir</span> Technical University</em></p>
<p>Track(s): R Production, R Life Sciences, R Applications</p>
<p><strong>Abstract:</strong></p>
<p>One-way ANOVA is used for testing equality of several population means in statistics, and current packages in R provides functions to apply it. However, the violation of its assumptions are normality and variance heterogeneity limits its use, also not possible in some cases. doex provides alternative statistical methods to solve this problem. It has several tests based on generalized p-value, parametric bootstrap and fiducial approaches for the violation of variance heterogeneity and normality. Moreover, it provides the newly proposed methods for testing equality of mean lifetimes under different failure rates.</p>
<p>This talk introduces doex package provides has several methods for testing equality of population means independently the strict assumptions of ANOVA. An illustrative example is given for testing equality of mean of product lifetimes under different failure rates.</p>
<p>Coauthor(s): Berna YAZICI .</p>
</div>
<div id="keeping-on-top-of-r-in-real-time-high-stakes-trading-systems" class="section level3">
<h3><span class="header-section-number">1.1.18</span> Keeping on top of R in Real-Time, High-Stakes trading systems</h3>
<p><strong>Nicholas Jhirad</strong>, <em>Senior Data Scientist, CINQ ICT (on Contract to Pinnacle Sports)</em></p>
<p>Track(s): R Production</p>
<p><strong>Abstract:</strong></p>
<p>Visibility is the key to production. For R to work inside that environment, we need ubiquitous logging. I’ll share insights from our experience building a production-grade R stack and monitoring all of our R applications via syslog, the ‘rsyslog’ package (on CRAN) and splunk.</p>
<p>Coauthor(s): Aaron Jacobs .</p>
</div>
<div id="towards-more-structured-data-quality-assessment-in-the-process-mining-field-the-daqapo-package" class="section level3">
<h3><span class="header-section-number">1.1.19</span> Towards more structured data quality assessment in the process mining field: the DaQAPO package</h3>
<p><strong>Niels Martin</strong>, <em>Postdoctoral researcher Research Foundation Flanders (FWO) - Hasselt University</em></p>
<p>Track(s): R Applications</p>
<p><strong>Abstract:</strong></p>
<p>Process mining is a research field focusing on the extraction of insights on business processes from process execution data embedded in files called event logs. Event logs are a specific data structure originating from information systems supporting a business process such as an Enterprise Resource Planning System or a Hospital Information System. As a research field, process mining predominantly focused on the development of algorithms to retrieve process insights from an event log. However, consistent with the “garbage in - garbage out”-principle, the reliability of the algorithm’s outcomes strongly depends upon the data quality of the event log. It has been widely recognized that real-life event logs typically suffer from a multitude of data quality issues, stressing the need for thorough data quality assessment. Currently, event log quality is often judged on an ad-hoc basis, entailing the risk that important issues are overlooked. Hence, the need for a more structured data quality assessment approach within the process mining field. Therefore, the DaQAPO package has been developed, which is an acronym for Data Quality Assessment of Process-Oriented data. It offers an extensive set of functions to automatically identify common data quality problems in process execution data. In this way, it is the first R-package which supports systematic data quality assessment for event data.</p>
<p>Coauthor(s): Niels Martin (Research Foundation Flanders FWO - Hasselt University), Greg Van Houdt (Hasselt University), Gert Janssenswillen (Hasselt University) .</p>
</div>
<div id="analyzing-preference-data-with-the-bayesmallows-package" class="section level3">
<h3><span class="header-section-number">1.1.20</span> Analyzing Preference Data with the BayesMallows Package</h3>
<p><strong>Øystein Sørensen</strong>, <em>Associate Professor, University of Oslo</em></p>
<p>Track(s): R Machine Learning &amp; Models</p>
<p><strong>Abstract:</strong></p>
<p>BayesMallows is an R package for analyzing preference data in the form of rankings with the Mallows rank model, and its finite mixture extension, in a Bayesian framework. The model is grounded on the idea that the probability density of an observed ranking decreases exponentially with the distance to the location parameter. It is the first Bayesian implementation that allows wide choices of distances, and it works well with a large number of items to be ranked. BayesMallows handles non-standard data: partial rankings and pairwise comparisons, even in cases including non-transitive preference patterns. The Bayesian paradigm allows coherent quantification of posterior uncertainties of estimates of any quantity of interest. These posteriors are fully available to the user, and the package comes with convenient tools for summarizing and visualizing the posterior distributions.</p>
<p>This talk will focus on how the BayesMallows package can be used to analyze preference data, in particular how the Bayesian paradigm allows endless possibilities in answering questions of interest with the help of visualization of posterior distributions. Such posterior summaries can easily be communicated with scientific collaborators and business stakeholders who may not be machine learning experts themselves.</p>
<p>Coauthor(s): Marta Crispino, Qinghua Liu, Valeria Vitelli .</p>
</div>
<div id="predicting-business-cycle-fluctuations-using-text-analytics" class="section level3">
<h3><span class="header-section-number">1.1.21</span> Predicting Business Cycle Fluctuations Using Text Analytics</h3>
<p><strong>Sami Diaf</strong>, <em>Researcher at the University of Hamburg</em></p>
<p>Track(s): R Machine Learning &amp; Models</p>
<p><strong>Abstract:</strong></p>
<p>The use of computational linguistics proved to be crucial in studying macroeconomic forecasts and understanding the essence of such exercises.</p>
<p>Combining machine learning algorithms with text mining pipelines helps dissecting potential patterns of forecast errors and investigates the role of ideology in such outcomes.</p>
<p>The Priority Program “Exploring the Experience-Expectation Nexus” builds up, from a large database of German business cycle reports, advanced topic models and predictive analytics to investigate the role of ideology in the production of macroeconomic forecasts. The pipelines call for advanced data processing, predicting business fluctuations from text covariates, measuring ideological stances of forecasters and explaining what influences forecast errors.</p>
</div>
<div id="flexible-deep-learning-via-the-juliaconnector" class="section level3">
<h3><span class="header-section-number">1.1.22</span> Flexible deep learning via the JuliaConnectoR</h3>
<p><strong>Stefan Lenz</strong>, <em>Statistician at the Institute of Medical Biometry and Statistics (IMBI), Faculty of Medicine and Medical Center – University of Freiburg</em></p>
<p>Track(s): R Machine Learning &amp; Models</p>
<p><strong>Abstract:</strong></p>
<p>For deep learning in R, frameworks from other languages, e. g. from Python, are widely used. Julia is another language which offers computational speed and a growing ecosystem for machine learning, e. g. with the package “Flux”. Integrating functionality of Julia in R is especially promising due to the many commonalities of Julia and R. We take advantage of these in the design of our “JuliaConnectoR” R package, which aims at a tight integration of Julia in R. We would like to present our package, together with some deep learning examples.
The JuliaConnectoR can import Julia functions, also from whole packages, and make them directly callable in R. Values and data structures are translated between the two languages. This includes the management of objects holding external resources such as memory pointers. The possibility to pass R functions as arguments to Julia functions makes the JuliaConnectoR a truly functional interface. Such callback functions can, e. g., be used to interactively display the learning process of a neural network in R while it is trained in Julia. Among others, this feature sets the JuliaConnectoR apart from the other R packages for integrating Julia in R, “XRJulia” and “JuliaCall”. This becomes possible with an optimized communication protocol, which also allows a highly efficient data transfer, leveraging the similarities in the binary representation of values in Julia and R.</p>
<p>Coauthor(s): Harald Binder .</p>
</div>
<div id="time-series-missing-data-visualizations" class="section level3">
<h3><span class="header-section-number">1.1.23</span> Time Series Missing Data Visualizations</h3>
<p><strong>Steffen Moritz</strong>, <em>Institute for Data Science, Engineering, and Analytics, TH Köln</em></p>
<p>Track(s): R Dataviz &amp; Shiny, R Applications</p>
<p><strong>Abstract:</strong></p>
<p>Missing data is a quite common problem for time series, which usually also complicates later analysis steps.
In order to deal with this problem, visualizing the missing data is a very good start.</p>
<p>Visualizing the patterns in the missing data can provide more information about the reasons for the missing data and give hints on how to best proceed with the analysis.</p>
<p>This talk gives a short intro into the new plotting functions being introduced with the 3.1 version of the imputeTS CRAN package.</p>
<p>Coauthor(s): Thomas Bartz-Beielstein .</p>
</div>
<div id="effectclass-an-r-package-to-interpret-effects-and-visualise-uncertainty" class="section level3">
<h3><span class="header-section-number">1.1.24</span> effectclass: an R package to interpret effects and visualise uncertainty</h3>
<p><strong>Thierry Onkelinx</strong>, <em>Statistician at the Research Institute for Nature and Forest</em></p>
<p>Track(s): R Dataviz &amp; Shiny</p>
<p><strong>Abstract:</strong></p>
<p>The package classifies effects by comparing their confidence interval with a reference, a lower and an upper threshold, all of which are set by the user a priori. The null hypothesis is a good choice as reference. The lower and upper threshold define a region around the reference in which the effect is small enough to be irrelevant. These thresholds are ideally based on the effect size used in the statistical power analysis of the design. Otherwise they can be based on expert judgement.</p>
<p>The result is a ten-scale classification of the effect. Three classes exist for significant effects above the reference and three classes for significant effects below the reference. The remaining four classes split the non-significant effects. The most important distinction is between “no effect” and “unknown effect”.</p>
<p>effectclass provides ggplot2 add-ons stat_effect() and scale_effect() to visualise the effects as points with shapes depending on the classification. It provides stat_fan() which displays the uncertainty as multiple overlapping intervals with different confidence probability. stat_fan() is inspired by Britton, E.; Fisher, P. &amp; J. Whitley (1998)</p>
<p>More details on the package website: <a href="https://effectclass.netlify.com/" class="uri">https://effectclass.netlify.com/</a></p>
<p>Britton, E.; Fisher, P. &amp; J. Whitley (1998). The Inflation Report Projections: Understanding the Fan Chart. Bank of England Quarterly Bulletin.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="erum2020-contributed-program.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="posters.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
